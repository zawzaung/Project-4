{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with LDA (count vectorizer) is explored here.  Though topics somewhat make sense, the top 10 words in each topic are not as relevant as to each other when compared to the top words from NMF (TF-IDF Vectroizer).  Thus, LDA topic modeling is not considered for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:22:47.065609Z",
     "start_time": "2020-02-26T22:22:46.496125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zaw/miniconda3/envs/metis/lib/python3.7/site-packages/socks.py:65: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "/Users/zaw/miniconda3/envs/metis/lib/python3.7/site-packages/gensim/corpora/dictionary.py:11: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "/Users/zaw/miniconda3/envs/metis/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:22:52.759976Z",
     "start_time": "2020-02-26T22:22:49.016972Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('dtm_stop.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:22:53.770853Z",
     "start_time": "2020-02-26T22:22:53.755213Z"
    }
   },
   "outputs": [],
   "source": [
    "tdm = data.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:22:59.249181Z",
     "start_time": "2020-02-26T22:22:56.459671Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:22:59.864335Z",
     "start_time": "2020-02-26T22:22:59.758499Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T05:47:44.913960Z",
     "start_time": "2020-02-26T05:47:32.737719Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.001*\"tapioca im\" + 0.001*\"good\" + 0.001*\"line long\" + 0.001*\"ridiculous long\" + 0.001*\"great\" + 0.001*\"line\" + 0.001*\"one hour\" + 0.000*\"wouldnt\" + 0.000*\"full\" + 0.000*\"charge\"'),\n",
       " (1,\n",
       "  '0.001*\"service\" + 0.001*\"first\" + 0.001*\"wait\" + 0.001*\"bobas\" + 0.001*\"table\" + 0.001*\"yall\" + 0.001*\"self\" + 0.001*\"self service\" + 0.001*\"ask\" + 0.001*\"know\"'),\n",
       " (2,\n",
       "  '0.001*\"wish\" + 0.000*\"must try\" + 0.000*\"richmond\" + 0.000*\"personal\" + 0.000*\"personal favorite\" + 0.000*\"great\" + 0.000*\"sunset\" + 0.000*\"werent\" + 0.000*\"try like\" + 0.000*\"side\"'),\n",
       " (3,\n",
       "  '0.003*\"cup\" + 0.002*\"tea\" + 0.002*\"good\" + 0.002*\"pretty\" + 0.002*\"huge\" + 0.001*\"milk\" + 0.001*\"boba\" + 0.001*\"wait\" + 0.001*\"dont\" + 0.001*\"also\"'),\n",
       " (4,\n",
       "  '0.001*\"puff\" + 0.001*\"cheese puff\" + 0.001*\"room sit\" + 0.000*\"always ice\" + 0.000*\"pant\" + 0.000*\"way last\" + 0.000*\"sweetened version\" + 0.000*\"golden gate\" + 0.000*\"gate park\" + 0.000*\"gate\"'),\n",
       " (5,\n",
       "  '0.009*\"wait\" + 0.008*\"boba\" + 0.005*\"line\" + 0.005*\"minute\" + 0.004*\"tea\" + 0.004*\"long\" + 0.004*\"waited\" + 0.002*\"good\" + 0.002*\"min\" + 0.002*\"worth\"'),\n",
       " (6,\n",
       "  '0.019*\"tea\" + 0.015*\"milk\" + 0.010*\"boba\" + 0.010*\"milk tea\" + 0.008*\"like\" + 0.008*\"line\" + 0.007*\"wait\" + 0.007*\"good\" + 0.005*\"cup\" + 0.005*\"long\"'),\n",
       " (7,\n",
       "  '0.001*\"minute cup\" + 0.001*\"nothing great\" + 0.001*\"bad ha\" + 0.000*\"hardly\" + 0.000*\"added tapioca\" + 0.000*\"closer house\" + 0.000*\"like kind\" + 0.000*\"walking distance\" + 0.000*\"pretty expensive\" + 0.000*\"like syrup\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=8, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T05:47:48.492299Z",
     "start_time": "2020-02-26T05:47:48.458183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tapioca im</td>\n",
       "      <td>service</td>\n",
       "      <td>wish</td>\n",
       "      <td>cup</td>\n",
       "      <td>puff</td>\n",
       "      <td>wait</td>\n",
       "      <td>tea</td>\n",
       "      <td>minute cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>first</td>\n",
       "      <td>must try</td>\n",
       "      <td>tea</td>\n",
       "      <td>cheese puff</td>\n",
       "      <td>boba</td>\n",
       "      <td>milk</td>\n",
       "      <td>nothing great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>line long</td>\n",
       "      <td>wait</td>\n",
       "      <td>richmond</td>\n",
       "      <td>good</td>\n",
       "      <td>room sit</td>\n",
       "      <td>line</td>\n",
       "      <td>boba</td>\n",
       "      <td>bad ha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridiculous long</td>\n",
       "      <td>bobas</td>\n",
       "      <td>personal</td>\n",
       "      <td>pretty</td>\n",
       "      <td>always ice</td>\n",
       "      <td>minute</td>\n",
       "      <td>milk tea</td>\n",
       "      <td>hardly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great</td>\n",
       "      <td>table</td>\n",
       "      <td>personal favorite</td>\n",
       "      <td>huge</td>\n",
       "      <td>pant</td>\n",
       "      <td>tea</td>\n",
       "      <td>like</td>\n",
       "      <td>added tapioca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>line</td>\n",
       "      <td>yall</td>\n",
       "      <td>great</td>\n",
       "      <td>milk</td>\n",
       "      <td>way last</td>\n",
       "      <td>long</td>\n",
       "      <td>line</td>\n",
       "      <td>closer house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>one hour</td>\n",
       "      <td>self</td>\n",
       "      <td>sunset</td>\n",
       "      <td>boba</td>\n",
       "      <td>sweetened version</td>\n",
       "      <td>waited</td>\n",
       "      <td>wait</td>\n",
       "      <td>like kind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wouldnt</td>\n",
       "      <td>self service</td>\n",
       "      <td>werent</td>\n",
       "      <td>wait</td>\n",
       "      <td>golden gate</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>walking distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>full</td>\n",
       "      <td>ask</td>\n",
       "      <td>try like</td>\n",
       "      <td>dont</td>\n",
       "      <td>gate park</td>\n",
       "      <td>min</td>\n",
       "      <td>cup</td>\n",
       "      <td>pretty expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>charge</td>\n",
       "      <td>know</td>\n",
       "      <td>side</td>\n",
       "      <td>also</td>\n",
       "      <td>gate</td>\n",
       "      <td>worth</td>\n",
       "      <td>long</td>\n",
       "      <td>like syrup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Topic # 01    Topic # 02         Topic # 03 Topic # 04  \\\n",
       "0       tapioca im       service               wish        cup   \n",
       "1             good         first           must try        tea   \n",
       "2        line long          wait           richmond       good   \n",
       "3  ridiculous long         bobas           personal     pretty   \n",
       "4            great         table  personal favorite       huge   \n",
       "5             line          yall              great       milk   \n",
       "6         one hour          self             sunset       boba   \n",
       "7          wouldnt  self service             werent       wait   \n",
       "8             full           ask           try like       dont   \n",
       "9           charge          know               side       also   \n",
       "\n",
       "          Topic # 05 Topic # 06 Topic # 07        Topic # 08  \n",
       "0               puff       wait        tea        minute cup  \n",
       "1        cheese puff       boba       milk     nothing great  \n",
       "2           room sit       line       boba            bad ha  \n",
       "3         always ice     minute   milk tea            hardly  \n",
       "4               pant        tea       like     added tapioca  \n",
       "5           way last       long       line      closer house  \n",
       "6  sweetened version     waited       wait         like kind  \n",
       "7        golden gate       good       good  walking distance  \n",
       "8          gate park        min        cup  pretty expensive  \n",
       "9               gate      worth       long        like syrup  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {};\n",
    "for i in range(8):\n",
    "    words = lda.show_topic(i, topn = 10)\n",
    "    word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words]\n",
    "pd.DataFrame(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling with nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:23:43.003811Z",
     "start_time": "2020-02-26T22:23:42.338396Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zaw/miniconda3/envs/metis/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/Users/zaw/miniconda3/envs/metis/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:24:32.635938Z",
     "start_time": "2020-02-26T22:24:32.631273Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:24:33.567937Z",
     "start_time": "2020-02-26T22:24:33.557048Z"
    }
   },
   "outputs": [],
   "source": [
    "data_clean = pd.read_pickle('data_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:24:45.173671Z",
     "start_time": "2020-02-26T22:24:34.845437Z"
    }
   },
   "outputs": [],
   "source": [
    "data_nouns = pd.DataFrame(data_clean.lem.apply(nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:24:46.605226Z",
     "start_time": "2020-02-26T22:24:46.602167Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:24:49.722399Z",
     "start_time": "2020-02-26T22:24:49.621028Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "newStopWords = ['purple','kow','drink','people','purple kow','place','wa','half','socal',\n",
    "                'norcal','something','menu','grass','time','make','even','another','order',\n",
    "               'sf','friend','back','get','got','came','come','went','go']\n",
    "stopwords.extend(newStopWords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stopwords)\n",
    "data_cvn = cvn.fit_transform(data_nouns.lem)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:25:10.679318Z",
     "start_time": "2020-02-26T22:25:10.485681Z"
    }
   },
   "outputs": [],
   "source": [
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:25:22.387645Z",
     "start_time": "2020-02-26T22:25:13.738625Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=8, id2word=id2wordn, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T06:01:45.367186Z",
     "start_time": "2020-02-26T06:01:45.352903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coconut</td>\n",
       "      <td>food</td>\n",
       "      <td>chicken</td>\n",
       "      <td>line</td>\n",
       "      <td>line</td>\n",
       "      <td>boba</td>\n",
       "      <td>cup</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tea</td>\n",
       "      <td>chicken</td>\n",
       "      <td>salt</td>\n",
       "      <td>tea</td>\n",
       "      <td>minute</td>\n",
       "      <td>line</td>\n",
       "      <td>tea</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dessert</td>\n",
       "      <td>customer</td>\n",
       "      <td>pepper</td>\n",
       "      <td>minute</td>\n",
       "      <td>tapioca</td>\n",
       "      <td>wait</td>\n",
       "      <td>milk</td>\n",
       "      <td>boba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food</td>\n",
       "      <td>yum</td>\n",
       "      <td>nugget</td>\n",
       "      <td>wait</td>\n",
       "      <td>service</td>\n",
       "      <td>tea</td>\n",
       "      <td>boba</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crema</td>\n",
       "      <td>business</td>\n",
       "      <td>snack</td>\n",
       "      <td>service</td>\n",
       "      <td>hour</td>\n",
       "      <td>milk</td>\n",
       "      <td>car</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>school</td>\n",
       "      <td>outer</td>\n",
       "      <td>stick</td>\n",
       "      <td>customer</td>\n",
       "      <td>wait</td>\n",
       "      <td>cup</td>\n",
       "      <td>holder</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tapioca</td>\n",
       "      <td>service</td>\n",
       "      <td>review</td>\n",
       "      <td>milk</td>\n",
       "      <td>fruit</td>\n",
       "      <td>minute</td>\n",
       "      <td>line</td>\n",
       "      <td>ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quality</td>\n",
       "      <td>milktea</td>\n",
       "      <td>hr</td>\n",
       "      <td>min</td>\n",
       "      <td>cup</td>\n",
       "      <td>hour</td>\n",
       "      <td>size</td>\n",
       "      <td>flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ice</td>\n",
       "      <td>fry</td>\n",
       "      <td>ice</td>\n",
       "      <td>cashier</td>\n",
       "      <td>door</td>\n",
       "      <td>pudding</td>\n",
       "      <td>minute</td>\n",
       "      <td>pudding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>boba</td>\n",
       "      <td>almond</td>\n",
       "      <td>piece</td>\n",
       "      <td>boba</td>\n",
       "      <td>way</td>\n",
       "      <td>door</td>\n",
       "      <td>wait</td>\n",
       "      <td>tapioca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic # 01 Topic # 02 Topic # 03 Topic # 04 Topic # 05 Topic # 06  \\\n",
       "0    coconut       food    chicken       line       line       boba   \n",
       "1        tea    chicken       salt        tea     minute       line   \n",
       "2    dessert   customer     pepper     minute    tapioca       wait   \n",
       "3       food        yum     nugget       wait    service        tea   \n",
       "4      crema   business      snack    service       hour       milk   \n",
       "5     school      outer      stick   customer       wait        cup   \n",
       "6    tapioca    service     review       milk      fruit     minute   \n",
       "7    quality    milktea         hr        min        cup       hour   \n",
       "8        ice        fry        ice    cashier       door    pudding   \n",
       "9       boba     almond      piece       boba        way       door   \n",
       "\n",
       "  Topic # 07 Topic # 08  \n",
       "0        cup        tea  \n",
       "1        tea       milk  \n",
       "2       milk       boba  \n",
       "3       boba       line  \n",
       "4        car       wait  \n",
       "5     holder      taste  \n",
       "6       line        ice  \n",
       "7       size     flavor  \n",
       "8     minute    pudding  \n",
       "9       wait    tapioca  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {};\n",
    "for i in range(8):\n",
    "    words = ldan.show_topic(i, topn = 10)\n",
    "    word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words]\n",
    "pd.DataFrame(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic modeling adjective and noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:25:23.345617Z",
     "start_time": "2020-02-26T22:25:23.340787Z"
    }
   },
   "outputs": [],
   "source": [
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:25:34.291386Z",
     "start_time": "2020-02-26T22:25:24.444169Z"
    }
   },
   "outputs": [],
   "source": [
    "data_nouns_adj = pd.DataFrame(data_clean.lem.apply(nouns_adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:25:36.456338Z",
     "start_time": "2020-02-26T22:25:36.357420Z"
    }
   },
   "outputs": [],
   "source": [
    "cvna = CountVectorizer(stop_words=stopwords, min_df=3)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.lem)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:25:39.689089Z",
     "start_time": "2020-02-26T22:25:39.614793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:49:37.118633Z",
     "start_time": "2020-02-26T22:25:44.705715Z"
    }
   },
   "outputs": [],
   "source": [
    "ldana = models.LdaModel(corpus=corpusna, num_topics=7, id2word=id2wordna, passes=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-26T22:49:57.787660Z",
     "start_time": "2020-02-26T22:49:57.767045Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boba</td>\n",
       "      <td>cup</td>\n",
       "      <td>line</td>\n",
       "      <td>tea</td>\n",
       "      <td>customer</td>\n",
       "      <td>bubble</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milk</td>\n",
       "      <td>boba</td>\n",
       "      <td>wait</td>\n",
       "      <td>milk</td>\n",
       "      <td>service</td>\n",
       "      <td>bad</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sweet</td>\n",
       "      <td>milk</td>\n",
       "      <td>minute</td>\n",
       "      <td>boba</td>\n",
       "      <td>minute</td>\n",
       "      <td>card</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pudding</td>\n",
       "      <td>tea</td>\n",
       "      <td>long</td>\n",
       "      <td>chicken</td>\n",
       "      <td>tapioca</td>\n",
       "      <td>crap</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tea</td>\n",
       "      <td>good</td>\n",
       "      <td>tea</td>\n",
       "      <td>good</td>\n",
       "      <td>tea</td>\n",
       "      <td>credit</td>\n",
       "      <td>boba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>line</td>\n",
       "      <td>size</td>\n",
       "      <td>hour</td>\n",
       "      <td>ive</td>\n",
       "      <td>cashier</td>\n",
       "      <td>isnt</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good</td>\n",
       "      <td>huge</td>\n",
       "      <td>good</td>\n",
       "      <td>great</td>\n",
       "      <td>milk</td>\n",
       "      <td>hey</td>\n",
       "      <td>matcha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic # 01 Topic # 02 Topic # 03 Topic # 04 Topic # 05 Topic # 06 Topic # 07\n",
       "0       boba        cup       line        tea   customer     bubble        tea\n",
       "1       milk       boba       wait       milk    service        bad       milk\n",
       "2      sweet       milk     minute       boba     minute       card      green\n",
       "3    pudding        tea       long    chicken    tapioca       crap      fresh\n",
       "4        tea       good        tea       good        tea     credit       boba\n",
       "5       line       size       hour        ive    cashier       isnt      sweet\n",
       "6       good       huge       good      great       milk        hey     matcha"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {};\n",
    "for i in range(7):\n",
    "    words = ldana.show_topic(i, topn = 7)\n",
    "    word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words]\n",
    "pd.DataFrame(word_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
