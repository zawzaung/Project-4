{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:01:34.069726Z",
     "start_time": "2020-02-25T08:01:32.770719Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:01:38.063166Z",
     "start_time": "2020-02-25T08:01:34.675438Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.yelp.com/biz/purple-kow-san-francisco-2'\n",
    "response = requests.get(url)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:10:39.110224Z",
     "start_time": "2020-02-25T08:01:44.383611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Scraping Page 2\n",
      "#review: 40 #rating: 40 #date: 40\n",
      "Finished Scraping Page 3\n",
      "#review: 60 #rating: 60 #date: 60\n",
      "Finished Scraping Page 4\n",
      "#review: 80 #rating: 80 #date: 80\n",
      "Finished Scraping Page 5\n",
      "#review: 100 #rating: 100 #date: 100\n",
      "Finished Scraping Page 6\n",
      "#review: 120 #rating: 120 #date: 120\n",
      "Finished Scraping Page 7\n",
      "#review: 140 #rating: 140 #date: 140\n",
      "Finished Scraping Page 8\n",
      "#review: 160 #rating: 160 #date: 160\n",
      "Finished Scraping Page 9\n",
      "#review: 180 #rating: 180 #date: 180\n",
      "Finished Scraping Page 10\n",
      "#review: 200 #rating: 200 #date: 200\n",
      "Finished Scraping Page 11\n",
      "#review: 220 #rating: 220 #date: 220\n",
      "Finished Scraping Page 12\n",
      "#review: 240 #rating: 240 #date: 240\n",
      "Finished Scraping Page 13\n",
      "#review: 260 #rating: 260 #date: 260\n",
      "Finished Scraping Page 14\n",
      "#review: 280 #rating: 280 #date: 280\n",
      "Finished Scraping Page 15\n",
      "#review: 300 #rating: 300 #date: 300\n",
      "Finished Scraping Page 16\n",
      "#review: 320 #rating: 320 #date: 320\n",
      "Finished Scraping Page 17\n",
      "#review: 340 #rating: 340 #date: 340\n",
      "Finished Scraping Page 18\n",
      "#review: 360 #rating: 360 #date: 360\n",
      "Finished Scraping Page 19\n",
      "#review: 380 #rating: 380 #date: 380\n",
      "Finished Scraping Page 20\n",
      "#review: 400 #rating: 400 #date: 400\n",
      "Finished Scraping Page 21\n",
      "#review: 420 #rating: 420 #date: 420\n",
      "Finished Scraping Page 22\n",
      "#review: 440 #rating: 440 #date: 440\n",
      "Finished Scraping Page 23\n",
      "#review: 460 #rating: 460 #date: 460\n",
      "Finished Scraping Page 24\n",
      "#review: 480 #rating: 480 #date: 480\n",
      "Finished Scraping Page 25\n",
      "#review: 500 #rating: 500 #date: 500\n",
      "Finished Scraping Page 26\n",
      "#review: 520 #rating: 520 #date: 520\n",
      "Finished Scraping Page 27\n",
      "#review: 540 #rating: 540 #date: 540\n",
      "Finished Scraping Page 28\n",
      "#review: 560 #rating: 560 #date: 560\n",
      "Finished Scraping Page 29\n",
      "#review: 580 #rating: 580 #date: 580\n",
      "Finished Scraping Page 30\n",
      "#review: 600 #rating: 600 #date: 600\n",
      "Finished Scraping Page 31\n",
      "#review: 620 #rating: 620 #date: 620\n",
      "Finished Scraping Page 32\n",
      "#review: 640 #rating: 640 #date: 640\n",
      "Finished Scraping Page 33\n",
      "#review: 660 #rating: 660 #date: 660\n",
      "Finished Scraping Page 34\n",
      "#review: 680 #rating: 680 #date: 680\n",
      "Finished Scraping Page 35\n",
      "#review: 700 #rating: 700 #date: 700\n",
      "Finished Scraping Page 36\n",
      "#review: 720 #rating: 720 #date: 720\n",
      "Finished Scraping Page 37\n",
      "#review: 740 #rating: 740 #date: 740\n",
      "Finished Scraping Page 38\n",
      "#review: 760 #rating: 760 #date: 760\n",
      "Finished Scraping Page 39\n",
      "#review: 780 #rating: 780 #date: 780\n",
      "Finished Scraping Page 40\n",
      "#review: 800 #rating: 800 #date: 800\n",
      "Finished Scraping Page 41\n",
      "#review: 820 #rating: 820 #date: 820\n",
      "Finished Scraping Page 42\n",
      "#review: 840 #rating: 840 #date: 840\n",
      "Finished Scraping Page 43\n",
      "#review: 860 #rating: 860 #date: 860\n",
      "Finished Scraping Page 44\n",
      "#review: 880 #rating: 880 #date: 880\n",
      "Finished Scraping Page 45\n",
      "#review: 900 #rating: 900 #date: 900\n",
      "Finished Scraping Page 46\n",
      "#review: 920 #rating: 920 #date: 920\n",
      "Finished Scraping Page 47\n",
      "#review: 940 #rating: 940 #date: 940\n",
      "Finished Scraping Page 48\n",
      "#review: 960 #rating: 960 #date: 960\n",
      "Finished Scraping Page 49\n",
      "#review: 980 #rating: 980 #date: 980\n",
      "Finished Scraping Page 50\n",
      "#review: 1000 #rating: 1000 #date: 1000\n",
      "Finished Scraping Page 51\n",
      "#review: 1020 #rating: 1020 #date: 1020\n",
      "Finished Scraping Page 52\n",
      "#review: 1040 #rating: 1040 #date: 1040\n",
      "Finished Scraping Page 53\n",
      "#review: 1060 #rating: 1060 #date: 1060\n",
      "Finished Scraping Page 54\n",
      "#review: 1080 #rating: 1080 #date: 1080\n",
      "Finished Scraping Page 55\n",
      "#review: 1100 #rating: 1100 #date: 1100\n",
      "Finished Scraping Page 56\n",
      "#review: 1120 #rating: 1120 #date: 1120\n",
      "Finished Scraping Page 57\n",
      "#review: 1140 #rating: 1140 #date: 1140\n",
      "Finished Scraping Page 58\n",
      "#review: 1160 #rating: 1160 #date: 1160\n",
      "Finished Scraping Page 59\n",
      "#review: 1180 #rating: 1180 #date: 1180\n",
      "Finished Scraping Page 60\n",
      "#review: 1200 #rating: 1200 #date: 1200\n",
      "Finished Scraping Page 61\n",
      "#review: 1220 #rating: 1220 #date: 1220\n",
      "Finished Scraping Page 62\n",
      "#review: 1240 #rating: 1240 #date: 1240\n",
      "Finished Scraping Page 63\n",
      "#review: 1260 #rating: 1260 #date: 1260\n",
      "Finished Scraping Page 64\n",
      "#review: 1280 #rating: 1280 #date: 1280\n",
      "Finished Scraping Page 65\n",
      "#review: 1300 #rating: 1300 #date: 1300\n",
      "Finished Scraping Page 66\n",
      "#review: 1320 #rating: 1320 #date: 1320\n",
      "Finished Scraping Page 67\n",
      "#review: 1340 #rating: 1340 #date: 1340\n",
      "Finished Scraping Page 68\n",
      "#review: 1360 #rating: 1360 #date: 1360\n",
      "Finished Scraping Page 69\n",
      "#review: 1380 #rating: 1380 #date: 1380\n",
      "Finished Scraping Page 70\n",
      "#review: 1400 #rating: 1400 #date: 1400\n",
      "Finished Scraping Page 71\n",
      "#review: 1420 #rating: 1420 #date: 1420\n",
      "Finished Scraping Page 72\n",
      "#review: 1440 #rating: 1440 #date: 1440\n",
      "Finished Scraping Page 73\n",
      "#review: 1460 #rating: 1460 #date: 1460\n",
      "Finished Scraping Page 74\n",
      "#review: 1480 #rating: 1480 #date: 1480\n",
      "Finished Scraping Page 75\n",
      "#review: 1500 #rating: 1500 #date: 1500\n",
      "Finished Scraping Page 76\n",
      "#review: 1520 #rating: 1520 #date: 1520\n",
      "Finished Scraping Page 77\n",
      "#review: 1540 #rating: 1540 #date: 1540\n",
      "Finished Scraping Page 78\n",
      "#review: 1560 #rating: 1560 #date: 1560\n",
      "Finished Scraping Page 79\n",
      "#review: 1580 #rating: 1580 #date: 1580\n",
      "Finished Scraping Page 80\n",
      "#review: 1600 #rating: 1600 #date: 1600\n",
      "Finished Scraping Page 81\n",
      "#review: 1620 #rating: 1620 #date: 1620\n",
      "Finished Scraping Page 82\n",
      "#review: 1640 #rating: 1640 #date: 1640\n",
      "Finished Scraping Page 83\n",
      "#review: 1660 #rating: 1660 #date: 1660\n",
      "Finished Scraping Page 84\n",
      "#review: 1680 #rating: 1680 #date: 1680\n",
      "Finished Scraping Page 85\n",
      "#review: 1700 #rating: 1700 #date: 1700\n",
      "Finished Scraping Page 86\n",
      "#review: 1720 #rating: 1720 #date: 1720\n",
      "Finished Scraping Page 87\n",
      "#review: 1740 #rating: 1740 #date: 1740\n",
      "Finished Scraping Page 88\n",
      "#review: 1760 #rating: 1760 #date: 1760\n",
      "Finished Scraping Page 89\n",
      "#review: 1780 #rating: 1780 #date: 1780\n",
      "Finished Scraping Page 90\n",
      "#review: 1800 #rating: 1800 #date: 1800\n",
      "Finished Scraping Page 91\n",
      "#review: 1820 #rating: 1820 #date: 1820\n",
      "Finished Scraping Page 92\n",
      "#review: 1840 #rating: 1840 #date: 1840\n",
      "Finished Scraping Page 93\n",
      "#review: 1860 #rating: 1860 #date: 1860\n",
      "Finished Scraping Page 94\n",
      "#review: 1880 #rating: 1880 #date: 1880\n",
      "Finished Scraping Page 95\n",
      "#review: 1900 #rating: 1900 #date: 1900\n",
      "Finished Scraping Page 96\n",
      "#review: 1920 #rating: 1920 #date: 1920\n",
      "Finished Scraping Page 97\n",
      "#review: 1940 #rating: 1940 #date: 1940\n",
      "Finished Scraping Page 98\n",
      "#review: 1960 #rating: 1960 #date: 1960\n",
      "Finished Scraping Page 99\n",
      "#review: 1980 #rating: 1980 #date: 1980\n",
      "Finished Scraping Page 100\n",
      "#review: 2000 #rating: 2000 #date: 2000\n",
      "Finished Scraping Page 101\n",
      "#review: 2020 #rating: 2020 #date: 2020\n",
      "Finished Scraping Page 102\n",
      "#review: 2040 #rating: 2040 #date: 2040\n",
      "Finished Scraping Page 103\n",
      "#review: 2060 #rating: 2060 #date: 2060\n",
      "Finished Scraping Page 104\n",
      "#review: 2080 #rating: 2080 #date: 2080\n",
      "Finished Scraping Page 105\n",
      "#review: 2100 #rating: 2100 #date: 2100\n",
      "Finished Scraping Page 106\n",
      "#review: 2120 #rating: 2120 #date: 2120\n",
      "Finished Scraping Page 107\n",
      "#review: 2140 #rating: 2140 #date: 2140\n",
      "Finished Scraping Page 108\n",
      "#review: 2160 #rating: 2160 #date: 2160\n",
      "Finished Scraping Page 109\n",
      "#review: 2180 #rating: 2180 #date: 2180\n",
      "Finished Scraping Page 110\n",
      "#review: 2200 #rating: 2200 #date: 2200\n",
      "Finished Scraping Page 111\n",
      "#review: 2220 #rating: 2220 #date: 2220\n",
      "Finished Scraping Page 112\n",
      "#review: 2240 #rating: 2240 #date: 2240\n",
      "Finished Scraping Page 113\n",
      "#review: 2260 #rating: 2260 #date: 2260\n",
      "Finished Scraping Page 114\n",
      "#review: 2280 #rating: 2280 #date: 2280\n",
      "Finished Scraping Page 115\n",
      "#review: 2300 #rating: 2300 #date: 2300\n",
      "Finished Scraping Page 116\n",
      "#review: 2320 #rating: 2320 #date: 2320\n",
      "Finished Scraping Page 117\n",
      "#review: 2340 #rating: 2340 #date: 2340\n",
      "Finished Scraping Page 118\n",
      "#review: 2347 #rating: 2347 #date: 2347\n"
     ]
    }
   ],
   "source": [
    "rating = []\n",
    "review = []\n",
    "date = []\n",
    "listclass = soup.find_all('li', {'class': 'lemon--li__373c0__1r9wz u-space-b3 u-padding-b3 border--bottom__373c0__uPbXS border-color--default__373c0__2oFDT'})\n",
    "\n",
    "for eachlist in listclass:\n",
    "    #find the star rating\n",
    "    rating_span = eachlist.find('span',{'class':'lemon--span__373c0__3997G display--inline__373c0__1DbOG border-color--default__373c0__2oFDT'})\n",
    "    star = rating_span.div['aria-label']\n",
    "    rating.append(int(star.replace(' star rating','')))\n",
    "    \n",
    "    date_span = eachlist.find('span', {'class':'lemon--span__373c0__3997G text__373c0__2pB8f text-color--mid__373c0__3G312 text-align--left__373c0__2pnx_'})\n",
    "    date.append(date_span.text)\n",
    "    \n",
    "    review_span = eachlist.find('span', {'class': 'lemon--span__373c0__3997G', 'lang':'en'})\n",
    "    review.append(review_span.text)\n",
    "    \n",
    "for i in range(20,2360,20):\n",
    "    url = 'https://www.yelp.com/biz/purple-kow-san-francisco-2?start={}'.format(i)\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    #Each user review is a list with a particular class.  \n",
    "    listclass = soup.find_all('li', {'class': 'lemon--li__373c0__1r9wz u-space-b3 u-padding-b3 border--bottom__373c0__uPbXS border-color--default__373c0__2oFDT'})\n",
    "\n",
    "    for eachlist in listclass:\n",
    "        #find the star ratings\n",
    "        rating_span = eachlist.find('span',{'class':'lemon--span__373c0__3997G display--inline__373c0__1DbOG border-color--default__373c0__2oFDT'})\n",
    "        star = rating_span.div['aria-label']\n",
    "        rating.append(int(star.replace(' star rating','')))\n",
    "        \n",
    "        #find the date\n",
    "        date_span = eachlist.find('span', {'class':'lemon--span__373c0__3997G text__373c0__2pB8f text-color--mid__373c0__3G312 text-align--left__373c0__2pnx_'})\n",
    "        date.append(date_span.text)\n",
    "        \n",
    "        #find the reviews\n",
    "        review_span = eachlist.find('span', {'class': 'lemon--span__373c0__3997G', 'lang':'en'})\n",
    "        review.append(review_span.text)\n",
    "    \n",
    "    pagenum = ((i/20)+1)\n",
    "    print('Finished Scraping Page',int(pagenum))\n",
    "    print('#review:',len(review),'#rating:',len(rating),'#date:',len(date))\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:10:48.712183Z",
     "start_time": "2020-02-25T08:10:48.706679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 2347\n",
      "rating: 2347\n",
      "review: 2347\n"
     ]
    }
   ],
   "source": [
    "print('date:',len(date))\n",
    "print('rating:',len(rating))\n",
    "print('review:',len(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:11:31.755233Z",
     "start_time": "2020-02-25T08:11:31.748877Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 10/6/2011   Star Rating: 5 \n",
      " Review: All the fruits are fresh and pureed on site, no sweet syrups, just the natural taste of the fresh fruit.  You can taste all the elements of the drink from the smooth green tea to the fresh peach puree with the wonderful texture of tapioca balls and coconut jelly in the Peach QQ drink.  I  really like the fact that all the fruit flavors are made from fresh fruit daily.  The desserts are made from fine ingredients too, like Callebaut chocolate, one of the best.  Sarah, the baker, and Kathy, the owner of Kam's are both tea masters, super friendly and the team that has brought this bright spot to the neighborhood and might even make it a destination.  Where else can you have a delicious Chinese meal (at Kam's restaurant where Purple Kow is an extension) followed by cappuccino, fruit infused tea, and european desserts without changing tables?\n"
     ]
    }
   ],
   "source": [
    "i = 2340\n",
    "print('Date:',date[i],' ','Star Rating:',rating[i],'\\n','Review:',review[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:11:41.710127Z",
     "start_time": "2020-02-25T08:11:41.702380Z"
    }
   },
   "outputs": [],
   "source": [
    "date_rating_review_PurpleKow = pd.DataFrame({'Date':date,'Star_Rating': rating,'Review': review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:11:42.509212Z",
     "start_time": "2020-02-25T08:11:42.489591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Star_Rating</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>10/6/2012</td>\n",
       "      <td>2</td>\n",
       "      <td>wtfffff been waiting for over 30mins since ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>11/5/2012</td>\n",
       "      <td>1</td>\n",
       "      <td>Now this is that many might have already read,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>1/16/2012</td>\n",
       "      <td>2</td>\n",
       "      <td>To anyone that calls in first to place an orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>3</td>\n",
       "      <td>the fruit slushs here at awesome, but the wait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>11/17/2011</td>\n",
       "      <td>5</td>\n",
       "      <td>so i didn't have a boba tea but their coconut ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Star_Rating  \\\n",
       "2342   10/6/2012            2   \n",
       "2343   11/5/2012            1   \n",
       "2344   1/16/2012            2   \n",
       "2345    1/3/2012            3   \n",
       "2346  11/17/2011            5   \n",
       "\n",
       "                                                 Review  \n",
       "2342  wtfffff been waiting for over 30mins since ope...  \n",
       "2343  Now this is that many might have already read,...  \n",
       "2344  To anyone that calls in first to place an orde...  \n",
       "2345  the fruit slushs here at awesome, but the wait...  \n",
       "2346  so i didn't have a boba tea but their coconut ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_rating_review_PurpleKow.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:11:52.057787Z",
     "start_time": "2020-02-25T08:11:52.054957Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-25T08:11:53.197515Z",
     "start_time": "2020-02-25T08:11:53.187913Z"
    }
   },
   "outputs": [],
   "source": [
    "#pickle for data cleaning\n",
    "with open('date_rating_review_PurpleKow.pickle', 'wb') as to_write:\n",
    "    pickle.dump(date_rating_review_PurpleKow, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
